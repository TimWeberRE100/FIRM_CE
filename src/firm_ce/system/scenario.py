import gc
from typing import Dict

import numpy as np
from numpy.typing import NDArray
from scipy.optimize import OptimizeResult

from firm_ce.common.helpers import parse_comma_separated
from firm_ce.constructors.component_cons import construct_Fleet_object
from firm_ce.constructors.parameter_cons import construct_ScenarioParameters_object
from firm_ce.constructors.topology_cons import construct_Network_object
from firm_ce.constructors.traces_cons import (
    load_datafiles_to_generators,
    load_datafiles_to_reservoirs,
    load_datafiles_to_network,
    unload_data_from_generators,
    unload_data_from_reservoirs,
    unload_data_from_network,
)
from firm_ce.fast_methods import static_m
from firm_ce.io.file_manager import DataFile
from firm_ce.io.validate import ModelData
from firm_ce.optimisation.solver import Solver
from firm_ce.system.parameters import ModelConfig


class Scenario:
    """
    Represents a single model scenario, including its static parameters, network, fleet,
    and associated datafiles. A scenario represents a single system that can undergo
    a capacity expansion optimisation.

    Attributes:
    -------
    logger (logging.Logger): Logger instance inherited from ModelData for scenario logging.
    results_dir (str): Directory path where results for this Scenario are written. Based upon the model name,
        a timestamp, and the scenario name.
    scenario_data (Dict[str, str]): Scenario-specific configuration loaded from ModelData.scenarios.
    id (int): A model-level identifier of the Scenario.
    name (str): A string providing the ordinary name of the Scenario.
    type (str): Scenario type that manages the type of optimisation for the Scenario.
    x0 (NDArray[np.float64] | None): Initial candidate solution vector for decision variables if provided. Otherwise, None.
    initial_population (NDArray[np.float64] | str): Initial population for the optimiser. If a CSV filename is provided in
        inputs it is loaded as a 2-dimensional array; otherwise the string 'latinhypercube' signals that a Latin Hypercube
        sample should be generated by the optimiser.
    network (Network): Represents the network topology (a collection of Lines, Routes, and Nodes) and associated information.
    static (ScenarioParameters): Represents the static parameters for a model scenario.
    fleet (Fleet): Represents a collection of Generators and Storage systems in the scenario.
    statistics (Statistics | None): Optional Statistics object that stores the results of an optimisation. Initialised as None.
        Statistics instance generated either after solving the Scenario or through direct instantiation using an initial guess
        vector (refer to `examples/model_build_and_statistics.py`).
    """

    def __init__(self, model_data: ModelData, scenario_id: int) -> None:
        """
        Initialise a Scenario instance.

        Notes:
        -------
        This special method:
        - Loads an initial candidate solution vector (x0) if one is provided in the `initial_guess.csv` config file. If no
        initial guess is provided, a None value is assigned and the optimiser will select a default value.
        - Loads an initial population (2-dimensional array) if a filename is provided in the `scenarios.csv` config file
        directing the model to a CSV containing the initial population (1 row per candidate solution). Otherwise, the string
        value 'latinhypercube' will direct the optimiser to initialise the first population using a Latin Hypercube.
        - Uses constructor functions to initialise jitclasses. These separate constructor functions ensure that variable
        typing is compatible with Numba prior to initialising a jitclass instance.
        - Initialises the statistics attribute as None. Statistics instance generated either after solving the Scenario or
        through direct instantiation using an initial guess vector (refer to `examples/model_build_and_statistics.py`).

        Parameters:
        -------
        model_data (ModelData): Container of all model inputs loaded from the config_directory for the Model instance.
        scenario_id (int): A model-level identifier of the Scenario.

        Returns:
        -------
        None.
        """
        self.logger, self.results_dir = model_data.logger, model_data.results_dir

        self.scenario_data = model_data.scenarios[scenario_id]

        self.id = scenario_id
        self.name = self.scenario_data["scenario_name"]
        self.type = self.scenario_data["type"]
        self.x0 = self.get_initial_guess(model_data.x0s)
        self.initial_population = self.get_initial_pop()

        self.network = construct_Network_object(
            self.get_scenario_dicts(model_data.nodes),
            self.get_scenario_dicts(model_data.lines),
            self.scenario_data["networksteps_max"],
        )
        self.static = construct_ScenarioParameters_object(self.scenario_data, len(self.network.nodes))
        self.fleet = construct_Fleet_object(
            self.get_scenario_dicts(model_data.generators),
            self.get_scenario_dicts(model_data.reservoirs),
            self.get_scenario_dicts(model_data.storages),
            self.get_scenario_dicts(model_data.fuels),
            self.network.minor_lines,
            self.network.nodes,
        )

        self.statistics = None

        self.assign_x_indices()

    def __repr__(self):
        return f"Scenario({self.id!r} {self.name!r})"

    def load_datafiles(self, all_datafiles: Dict[str, DataFile], data_directory: str) -> None:
        """
        Load and attach external timeseries datafiles from the data_directory required by the
        Network.nodes and Fleet.generators for this Scenario. Calculates the annual net operational
        demand for each year in the modelling horizon.

        Parameters:
        -------
        all_datafiles (Dict[str, DataFile]): DataFile containers for all scenarios, keyed by the identifier specified in
            `datafiles.csv` config file.
        data_directory (str): Root directory where data files referenced by the DataFile values reside. When solving a Model
            instance, the data_directory is defined during Model instantiation.

        Returns:
        -------
        None

        Side-effects:
        -------
        Attributes modified for the referenced Scenario.network.nodes: data_status, data, residual_load.
        Attributes modified for the referenced Scenario.fleet.generators: data_status, data, annual_constraints_data.
        Attributes modified for the referenced Scenario.static: year_energy_demand.
        """
        datafiles = self.get_datafiles(all_datafiles, data_directory)

        load_datafiles_to_network(self.network, datafiles)

        load_datafiles_to_generators(self.fleet, datafiles, self.static.resolution)
        load_datafiles_to_reservoirs(self.fleet, datafiles)

        static_m.set_year_energy_demand(self.static, self.network.nodes)

        return None

    def unload_datafiles(self) -> None:
        """
        Unload the external timeseries datafiles from the Network.nodes and Fleet.generators for this Scenario. Clears
        the annual net operational demand from the ScenarioParameters instance for the Scenario. Invoked to free
        memory which is no longer required.

        Parameters:
        -------
        None.

        Returns:
        -------
        None.

        Side-effects:
        -------
        Attributes modified for the referenced Scenario.network.nodes: data_status, data, residual_load.
        Attributes modified for the referenced Scenario.fleet.generators: data_status, data, annual_constraints_data.
        Attributes modified for the referenced Scenario.static: year_energy_demand.
        Python garbage collector called to force the reclaimation of memory.
        """
        unload_data_from_network(self.network)

        unload_data_from_generators(self.fleet)
        unload_data_from_reservoirs(self.fleet)

        static_m.unset_year_energy_demand(self.static)

        gc.collect()

        return None

    def get_scenario_dicts(self, imported_dict: Dict[str, Dict[str, str]]) -> Dict[str, str]:
        """
        Filter items in a dictionary of imported config data, based upon whether the Scenario.name is in the list of
        scenario names associated with that item.

        Parameters:
        -------
        imported_dict (Dict[str, Dict[str, str]]): Raw data imported from a config file for the Model. Each row of a
            config file is associated with an item in the imported_dict.

        Returns:
        -------
        Dict[str, str]: Filtered data from a config file assigned to this Scenario instance, keyed by model-level ID.
        """
        return {
            idx: imported_dict[idx]
            for idx in imported_dict
            if self.name in parse_comma_separated(imported_dict[idx]["scenarios"])
            or parse_comma_separated(imported_dict[idx]["scenarios"]) == ["all"]
        }

    def get_datafiles(self, all_datafiles: Dict[str, Dict[str, str]], data_directory: str) -> Dict[str, DataFile]:
        """
        Filter items in the dictionary of all Model datafile details, based upon whether the Scenario.name is in the list of
        scenario names associated with that item. Construct the DataFile containers for the filtered items and import the
        associated timeseries data from the data_directory.

        Parameters:
        -------
        all_datafiles (Dict[str, Dict[str, str]]): Raw data imported from the `datafiles.csv` config file for the Model. Each
            row of the config file is associated with an item in all_datafiles.
        data_directory (str): Path to the data repository. When solving a Model instance, the data_directory is set when
            initialising the Model. Alternatively, the data_directory can be set directly when loading data for a
            Scenario prior to generating Statistics for an initial guess (refer to `examples/model_build_and_statistics.py`).

        Returns:
        -------
        Dict[str, DataFile]: Dictionary of DataFile containers with loaded timeseries data associated with this Scenario
            instance, keyed by model-level ID of the datafiles.
        """
        return {
            idx: DataFile(all_datafiles[idx]["filename"], all_datafiles[idx]["datafile_type"], data_directory)
            for idx in all_datafiles
            if self.name in parse_comma_separated(all_datafiles[idx]["scenarios"])
            or parse_comma_separated(all_datafiles[idx]["scenarios"]) == ["all"]
        }

    def get_initial_guess(self, all_x0s: Dict[str, Dict[str, str]]) -> NDArray[np.float64] | None:
        """
        Parse the dictionary defining initial candidate solution guesses for each Scenario. If an initial guess is provided
        for this Scenario, return the vector as an NDArray. Otherwise, return an empty NDArray.

        Parameters:
        -------
        all_x0s (Dict[str, Dict[str, str]]): Raw data imported from the `initial_guess.csv` config file for the Model. Each
            row of the config file is associated with an item in all_x0s (and should correspond to a single Scenario in the
            model).

        Returns:
        -------
        NDArray[np.float64]: A 1-dimensional array containing the initial candidate solution guess for the scenario. If the
            initial guess was blank for the Scenario, the NDArray is empty.
        None: Returned if scenario is not a key in the initial guess dictionary.
        """
        for entry in all_x0s.values():
            if entry["scenario"] == self.name:
                if isinstance(entry["x_0"], float) and np.isnan(entry["x_0"]):
                    x0_list = []
                else:
                    x0_str = entry["x_0"].strip()
                    x0_list = [float(x) for x in x0_str.split(",") if x.strip()]
                return np.array(x0_list, dtype=np.float64)
        return None

    def get_initial_pop(self) -> NDArray[np.float64] | str:
        """
        If an initial population filename has been provided for the scenario (in `scenarios.csv`), load that initial population from
        the specified file into a 2-dimensional array. If no initial population filename is provided, a default Latin Hypercube is
        assumed for the optimiser.

        Notes:
        -------
        The initial population CSV provided for each Scenario is required to contain numeric values with no header.

        Parameters:
        -------
        None.

        Returns:
        -------
        NDArray[np.float64]: A 2-dimensional array containing the initial population for the optimiser is returned if an initial
            population filename is assigned to the Scenario. Each row represents a separate candidate solution in the population,
            each column represents a different decision variable.
        str: A default value of "latinhypercube" is returned if no initial population filename is assigned to the Scenario.
        """
        if np.isnan(self.scenario_data["initial_pop_filename"]):
            filename = None
        else:
            filename = self.scenario_data["initial_pop_filename"]

        if filename:
            return np.loadtxt(filename, delimiter=",")
        else:
            return "latinhypercube"

    def assign_x_indices(self) -> None:
        """
        Assigns indices to each Generator, Storage and major Line object in the Scenario associating each element in the candidate
        solution vector with the relevant asset. Each element in the candidate solution represents the new build power capacities
        (Generator, Storage and Line) and new build energy capacities (Storage). These indices must be assigned in the same order
        as the definitions of the lower bound and upper bound vectors in the Solver instance.

        Parameters:
        -------
        None.

        Returns:
        -------
        None.

        Side-effects:
        -------
        Attributes modified for each asset referenced in Scenario.fleet.generators and Scenario.network.major_lines:
            candidate_x_idx.
        Attributes modified for each Storage referenced in Scenario.fleet.storages: candidate_p_x_idx, candidate_e_x_idx.
        """
        x_index = 0
        for generator in self.fleet.generators.values():
            generator.candidate_x_idx = x_index
            x_index += 1
        for reservoir in self.fleet.reservoirs.values():
            reservoir.candidate_p_x_idx = x_index
            x_index += 1
        for reservoir in self.fleet.reservoirs.values():
            reservoir.candidate_e_x_idx = x_index
            x_index += 1
        for storage in self.fleet.storages.values():
            storage.candidate_p_x_idx = x_index
            x_index += 1
        for storage in self.fleet.storages.values():
            storage.candidate_e_x_idx = x_index
            x_index += 1
        for line in self.network.major_lines.values():
            line.candidate_x_idx = x_index
            x_index += 1
        return None

    def solve(self, config: ModelConfig) -> OptimizeResult:
        """
        Builds a Solver object and evaluates the solution. The type of optimisation is defined by the Model.type.

        Parameters:
        -------
        config (ModelConfig): Data class for model configuration parameters loaded from CSV input.

        Returns:
        -------
        OptimizeResult: Represents the SciPy optimization result. Includes the population, population energies, and
            best solution.

        Side-effects:
        -------
        Generates temporary result files using the callback function of the optimiser. These files are stored in
        `results/temp` and include the most recently evaluated population (`final_population.csv`), the full set
        of candidate solutions evaluated (`populations.csv`), the energies of each population (`population_energies.csv`),
        and the best candidate solution from each iteration of the optimisation (`callback.csv`).
        """
        solver = Solver(
            config, self.x0, self.static, self.fleet, self.network, self.logger, self.name, self.initial_population
        )
        solver.evaluate()
        return solver.result
